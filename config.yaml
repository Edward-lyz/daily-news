arxiv:
  # Start broad; refine once the pipeline runs reliably.
  query: '(cat:cs.LG OR cat:cs.DC OR cat:cs.PF) AND (GPU OR CUDA OR "distributed training" OR inference OR serving OR kernel)'
  max_results: 80
  top_n: 15

github:
  repos:
    - "deepseek-ai/DeepGEMM"
    - "deepseek-ai/FlashMLA"
    - "NVIDIA/cutlass"
    - "flashinfer-ai/flashinfer"
    - "Dao-AILab/flash-attention"
    - "sgl-project/sglang"
    - "vllm-project/vllm"
  max_commits_per_repo: 16
  max_files_per_commit: 16
  max_diff_chars: 1200
  max_total_diff_chars: 20000
  max_issues_per_repo: 8
  max_issue_body_chars: 800
  max_total_issue_body_chars: 12000

openrouter:
  # Choose free/low-cost models to try in order.
  models:
    - "z-ai/glm-4.5-air:free"
    - "moonshotai/kimi-k2:free"
    - "openai/gpt-oss-120b:free"
    - "deepseek/deepseek-r1-0528:free"
    - "qwen/qwen3-coder:free"
  retry_max: 3
  retry_base_seconds: 10
