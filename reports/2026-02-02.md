## 摘要

本周AI基础设施领域的主要进展集中在高性能计算库的优化和新硬件支持上。FlashInfer修复了JIT目录生成问题并改进了日志功能，SGLang添加了多个JIT内核并优化了缓存性能，vLLM则改进了多模态处理和LoRA操作效率。

## 具体内容分析

### FlashInfer
- **修复JIT目录生成问题** ([PR #2445](https://github.com/flashinfer-ai/flashinfer/commit/3fa8905c79fe3b711ff62af5bab5e3cc5ec6d5ea))
  - 修正了fused_moe模块中写入包目录的问题，这些目录在安装后可能为只读
  - 添加了JIT目录规则文档，明确区分可写和只读目录
  - 代码修改：使用`FLASHINFER_GEN_SRC_DIR`替代`FLASHINFER_CSRC_DIR`

- **改进日志功能** ([PR #2449](https://github.com/flashinfer-ai/flashinfer/commit/806339fbbd5c77ae01889ddef303e59bb503c7d7))
  - 修复`set_log_level`函数，确保正确设置日志级别以启用DEBUG日志
  - 添加`spdlog::set_level(lvl)`调用

### SGLang
- **添加JIT MLA内核** ([PR #17889](https://github.com/sgl-project/sglang/commit/9b1619c148a0a800e9ddb3d2e42ff32ee2dd2679))
  - 新增多头潜在注意力(MLA)的JIT内核实现
  - 包含基准测试、核心实现和测试文件
  - 优化了MLA操作的效率

- **支持DeepSeek v32 CPU卸载** ([PR #17415](https://github.com/sgl-project/sglang/commit/180594358b990b2a5ce8140fb64aae90d73910fd))
  - 在HiCache中添加对NSATokenToKVPool的支持
  - 扩展了CPU内存管理能力

- **添加QKNorm跨头内核** ([PR #18073](https://github.com/sgl-project/sglang/commit/a1bbc892af27867901f91e9a1c485824ff9337a6))
  - 新增JIT内核实现QK跨头归一化
  - 提供了基准测试和CUDA实现

- **优化基数缓存驱逐性能** ([PR #14339](https://github.com/sgl-project/sglang/commit/fd983b09b68c076d448a55266a29ffdfdff2d06e))
  - 改进了缓存驱逐算法
  - 优化了内存管理效率

### VLLM
- **减少LoRA操作的内核开销** ([PR #32005](https://github.com/vllm-project/vllm/commit/ffe1fc7a28841973135b981fb68ce515b409a236))
  - 当活动LoRA数量小于最大值时减少内核开销
  - 为每个活动LoRA数量捕获多个CUDA图

- **支持Fabric检测** ([PR #33540](https://github.com/vllm-project/vllm/commit/528e9b14900fc8a012f2599172e2a4576caafe1a))
  - 为GB系列添加Fabric检测以适应MNNVL协议
  - 增强了硬件兼容性

- **启用潜在MoE的共享/路由重叠** ([PR #32790](https://github.com/vllm-project/vllm/commit/0aca8b8c628e9a73ab8758d78c9c721bc703ee66))
  - 为Nemotron-H模型添加支持
  - 提高了MoE模型的处理效率

## 问题与挑战

1. **FlashInfer**:
   - `trtllm_fp8_per_tensor_scale_moe`不支持float32类型的routing_logits
   - 用户请求强制PTX代码执行而非预编译SASS

2. **Flash-Attention**:
   - 缺少Blackwell架构支持
   - 发布版whl文件存在导入错误

3. **SGLang**:
   - GLM 4.6 FP8模型在flash infer后端存在KV缓存卸载问题
   - 需要为/v1/score API返回token使用情况
   - 启用分段CUDA图(PCG)的待办事项列表

4. **VLLM**:
   - 由于reasoning_content重命名为reasoning，导致聊天模板回归
   - 与PyTorch nightly的CI构建信号丢失
   - 依赖兼容性问题影响下游生态系统

总体而言，本周的进展主要集中在性能优化、新硬件支持和问题修复上，为AI推理基础设施提供了更稳定和高效的解决方案。
