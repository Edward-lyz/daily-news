ä»Šæ—¥çš„ AI Infra çš„æ–°é—»å¦‚ä¸‹ã€‚

## æ‘˜è¦
æœ¬å‘¨ **NVIDIA/cutlass** å¼•å…¥äº† `sub_packed_f32x2`ã€`multicast` å‚æ•°ä»¥åŠ `fmin` ç®—å­ï¼Œæå‡äº† CuTe DSL å¯¹ packed ç±»å‹å’Œå¤šè·¯å¤ç”¨çš„æ”¯æŒï¼›**flashinfer** å®Œæˆäº† FP8 BlockScale GEMMã€SM100 MXFP8 ä»¥åŠé‡‡æ ·æ¥å£çš„ CUDAâ€‘Graph æ”¹è¿›ï¼Œæ˜¾è‘—å¢å¼ºäº†ä½ç²¾åº¦æ¨ç†å’Œå›¾è°ƒåº¦çš„çµæ´»æ€§ï¼›**sglang** å°† FlashInfer ç‰ˆæœ¬å‡çº§è‡³ 0.6.3ã€ä¼˜åŒ–äº†æ¨¡å‹åŠ è½½çš„å¤šçº¿ç¨‹å®‰å…¨ã€åŠ å…¥äº† GPTQâ€‘Marlin JIT é‡æ‰“åŒ…ä»¥åŠ RotaryEmbedding JITï¼Œå®ç°äº†æ›´å¿«çš„æƒé‡è¯»å–å’Œä½ç½®ç¼–ç ï¼›**vllm** åœ¨æ··åˆæ¨¡å¼ã€CPU offloadã€Pipeline Parallelã€Mamba cache å¯¹é½ä»¥åŠå¤šæ¨¡æ€é…ç½®ä¸Šåšäº†å¤§é‡ä»£ç è¡¥å…¨å’Œæ€§èƒ½è°ƒä¼˜ï¼Œæ–°å¢å¯¹ Kimiâ€‘K2.5 ViTã€Qwen3.5ã€Helion è‡ªåŠ¨è°ƒä¼˜ç­‰æ¨¡å‹çš„åŸç”Ÿæ”¯æŒï¼›**cutileâ€‘python** ä»…ä¿®å¤äº†ä¸´æ—¶ç›®å½•åˆ›å»ºçš„ç»†èŠ‚ã€‚æ•´ä½“æ¥çœ‹ï¼Œä½ç²¾åº¦ï¼ˆFP8/SM120ï¼‰å’Œå¤šæ¨¡æ€/å¹¶è¡Œæ‰§è¡Œçš„åŠŸèƒ½æŒç»­æ‰©å±•ï¼Œä»£ç åŸºåº§çš„å¯ç»´æŠ¤æ€§å’Œ CI ç¨³å®šæ€§ä¹Ÿåœ¨åŒæ­¥æå‡ã€‚

## å…·ä½“å†…å®¹åˆ†æ
### deepseek-ai/DeepGEMM
æ˜¨æ—¥æ— æ›´æ–°ã€‚
### deepseek-ai/FlashMLA
æ˜¨æ—¥æ— æ›´æ–°ã€‚
### NVIDIA/cutlass
**æäº¤**

| SHA | PR | ç®€è¦è¯´æ˜ | å…³è”æ–‡ä»¶ |
|-----|----|----------|----------|
| `01687cf` | [#3004](https://github.com/NVIDIA/cutlass/pull/3004) | æ–°å¢ `sub_packed_f32x2` ç®—å­ï¼Œå®ç° packedâ€‘f32x2 çš„å‡æ³•ã€‚ | `python/CuTeDSL/cutlass/cute/arch/__init__.py`ï¼ˆåŠ å…¥ `sub_packed_f32x2` å¯¼å‡ºï¼‰<br>`python/CuTeDSL/cutlass/cute/arch/nvvm_wrappers.py`ï¼ˆåœ¨ `calc_packed_f32x2_op` ä¸­åˆ›å»º `sub_packed_f32x2` çš„ partialï¼‰ |
| `5c42d0f` | [#3021](https://github.com/NVIDIA/cutlass/pull/3021) | ä¸º `issue_clc_query` æ·»åŠ  `multicast` å‚æ•°ï¼Œæ”¯æŒéå¤šæ’­è·¯å¾„ã€‚ | `python/CuTeDSL/cutlass/cute/arch/clc.py`ï¼ˆæ–°å¢ `multicast: bool = True` å‚æ•°å¹¶åœ¨å†…éƒ¨æ ¹æ®è¯¥æ ‡å¿—è°ƒç”¨ `nvvm.clusterlaunchcontrol_try_cancel` æˆ– `..._multicast`ï¼‰ |
| `1d36152` | [#3022](https://github.com/NVIDIA/cutlass/pull/3022) | å¼•å…¥ `fmin` ç®—å­ï¼Œæä¾›æµ®ç‚¹æœ€å°å€¼è®¡ç®—ã€‚ | `python/CuTeDSL/cutlass/cute/arch/nvvm_wrappers.py`ï¼ˆå®ç° `fmin` å¹¶ä½¿ç”¨ `nvvm.fmin`ï¼‰ |

**Issues**

| æ ‡é¢˜ | é“¾æ¥ | ä½œè€… | åˆ›å»ºæ—¶é—´ | ç®€è¦éœ€æ±‚ |
|------|------|------|----------|----------|
| [FEA] Assume leading dim when size 1 = | https://github.com/NVIDIA/cutlass/issues/3031 | drisspg | 2026â€‘02â€‘13 23:10:51 UTC | åœ¨ `CuTe DSL` ä¸­ï¼Œ`tensor.mark_layout_dynamic()` æ— æ³•æ¨æ–­ leading dimensionï¼Œéœ€åœ¨ size ä¸º 1 æ—¶é»˜è®¤ä½¿ç”¨è¯¥ç»´åº¦ã€‚ |
| [FEA] Add CopyReduceBulkS2G | https://github.com/NVIDIA/cutlass/issues/3029 | tridao | 2026â€‘02â€‘13 19:22:08 UTC | éœ€è¦åœ¨ DSL ä¸­åŠ å…¥ `CopyReduceBulkS2G`ï¼ˆå¯¹åº” PTX `cp.reduce.async.bulk.global.share`ï¼‰ï¼Œç”¨äº FlashAttention ä¸­çš„ dQ reductionï¼Œå½“å‰åªèƒ½æ‰‹å†™ PTXã€‚ |
### flashinfer-ai/flashinfer
**æäº¤**  

- **292f9be** â€“ *fix: include fp8_blockscale_gemm_90 in AOT jitâ€‘cache*  
  - ä½œè€…ï¼šEdwardâ€ƒæ—¥æœŸï¼š2026â€‘02â€‘13 04:29:43â€¯UTC  
  - PR: <https://github.com/flashinfer-ai/flashinfer/pull/2533>  
  - å…³é”®æ–‡ä»¶ï¼š`flashinfer/aot.py`  
    ```diff
    +    gen_fp8_blockscale_gemm_sm90_module,
         ...
    +    # fp8 blockscale GEMM (SM90)
    +    jit_specs.append(gen_fp8_blockscale_gemm_sm90_module())
    ```
- **c5b8a2e** â€“ *fix: Sampling: CUDA Graph fix*  
  - ä½œè€…ï¼šIzzy Puttermanâ€ƒæ—¥æœŸï¼š2026â€‘02â€‘13 00:55:46â€¯UTC  
  - PR: <https://github.com/flashinfer-ai/flashinfer/pull/2432>  
  - å…³é”®æ–‡ä»¶ï¼š`flashinfer/sampling.py`ï¼ˆPython æ¥å£ï¼‰  
    ```diff
    -        seed: Optional[int] = None,
    -        offset: Optional[int] = None,
    +        seed: Optional[Union[int, torch.Tensor]] = None,
    +        offset: Optional[Union[int, torch.Tensor]] = None,
    ...
    +        maybe_seed_arr, seed_val, maybe_offset_arr, offset_val = (
    +            _validate_and_convert_seed_offset(seed, offset, device, batch_size)
    +        )
    ```
  - å…³é”®æ–‡ä»¶ï¼š`include/flashinfer/sampling.cuh`ï¼ˆCUDA kernelï¼‰  
    ```diff
    -                                         uint64_t philox_seed, uint64_t philox_offset) {
    +                                         uint64_t* seed_arr, uint64_t seed_val,
    +                                         uint64_t* offset_arr, uint64_t offset_val) {
    +  uint64_t philox_seed = seed_arr ? seed_arr[0] : seed_val;
    +  uint64_t philox_offset = offset_arr ? offset_arr[0] : offset_val;
    ```
- **2fff6b6** â€“ *Add gen_gemm_sm100_module_cutlass_mxfp8 to jitâ€‘cache*  
  - ä½œè€…ï¼šYong Wuâ€ƒæ—¥æœŸï¼š2026â€‘02â€‘13 00:25:54â€¯UTC  
  - PR: <https://github.com/flashinfer-ai/flashinfer/pull/2549>  
  - å…³é”®æ–‡ä»¶ï¼š`flashinfer/aot.py`  
    ```diff
    +    gen_gemm_sm100_module_cutlass_mxfp8,
         ...
    +    jit_specs.append(gen_gemm_sm100_module_cutlass_mxfp8())
    ```

**Issues**  

- **griddepcontrol.wait should use "memory" clobber**  
  - URL: <https://github.com/flashinfer-ai/flashinfer/issues/2558>  
  - ä½œè€…ï¼šMatthiasKohlâ€ƒåˆ›å»ºæ—¶é—´ï¼š2026â€‘02â€‘13 10:08:59â€¯UTC  
  - ç®€è¦ï¼šæŒ‡å‡º `griddepcontrol.wait` éœ€è¦ä½¿ç”¨ `"memory"` clobberï¼Œå¦åˆ™ä¼šå¯¼è‡´æœªå®šä¹‰è¡Œä¸ºï¼›å¹¶å»ºè®®ç›´æ¥ä½¿ç”¨å®˜æ–¹çš„ `cudaTriggerProgrammaticLaunchCompletion` / `cudaGridDependencySynchronize` åŒ…è£…å‡½æ•°ã€‚

- **`trtllm_batch_context_with_kv_cache` uses SM103 cubin but not `trtllm_batch_decode_with_kv_cache`**  
  - URL: <https://github.com/flashinfer-ai/flashinfer/issues/2556>  
  - ä½œè€…ï¼šb8zhongâ€ƒåˆ›å»ºæ—¶é—´ï¼š2026â€‘02â€‘13 02:47:28â€¯UTC  
  - ç®€è¦ï¼šè¯¢é—®ä¸ºä½• SM103 å˜ä½“ä»…åœ¨ context é˜¶æ®µæä¾› cubinï¼Œè€Œ decode é˜¶æ®µç¼ºå¤±ï¼Œæ€€ç–‘ä¸ FP4 æŒ‡ä»¤æ”¯æŒæœ‰å…³ã€‚

- **SM120 attention kernels exist but are blocked by wiring issues (fmha_v2, backend selector, MLA)**  
  - URL: <https://github.com/flashinfer-ai/flashinfer/issues/2555>  
  - ä½œè€…ï¼šblake-sncâ€ƒåˆ›å»ºæ—¶é—´ï¼š2026â€‘02â€‘13 01:44:39â€¯UTC  
  - ç®€è¦ï¼šæŠ¥å‘Š SM120 æ³¨æ„åŠ› kernel å·²å®ç°ä½†æœªåœ¨è¿è¡Œæ—¶è·¯å¾„ä¸­å¯ç”¨ï¼Œåˆ—å‡ºä¸‰å¤„ gating ä»£ç ï¼ˆ`ENABLE_SM120` ç¯å¢ƒå˜é‡ã€åç«¯é€‰æ‹©å™¨ã€MLA å…¥å£ï¼‰éœ€ä¿®å¤ã€‚
### Dao-AILab/flash-attention
æ˜¨æ—¥æ— æ›´æ–°ã€‚
### sgl-project/sglang
**æäº¤**  

- **#18448** â€“ å°† FlashInfer ç‰ˆæœ¬å‡çº§è‡³ 0.6.3ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`.github/workflows/release-docker-cu13-framework.yml`ï¼ˆ`flashinfer_version` é»˜è®¤å€¼ä» `0.6.1` æ”¹ä¸º `0.6.3`ï¼‰  
  - `Dockerfile` ä¸­ `ARG FLASHINFER_VERSION=0.6.3`  
  - `python/pyproject.toml` ä¸­ä¾èµ– `flashinfer_python==0.6.3`ã€`flashinfer_cubin==0.6.3`  
  - ç›¸å…³ä»£ç æ£€æŸ¥ `engine.py`ã€`server_args.py`ã€`common.py`ã€`ci_install_dependency.sh` ä¸­çš„ç‰ˆæœ¬å·å‡åŒæ­¥æ›´æ–°ã€‚  
  - **Commit**: `1be41e9` â€“ https://github.com/sgl-project/sglang/commit/1be41e9036e19fc620d39e8f7b22572fa36751a9  

- **#18817** â€“ æ›´æ–° Slack é€šçŸ¥ä¸­è¢«æåŠçš„ç”¨æˆ· IDã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`scripts/ci_monitor/post_ci_failures_to_slack.py`ï¼ˆ`mentions` ä» `<@U09RR5TNC94>` æ”¹ä¸º `<@U09R55D8EAY>`ï¼‰  
  - **Commit**: `710d873` â€“ https://github.com/sgl-project/sglang/commit/710d873ba6f3fc47e3af3ef7f6c219f396b98238  

- **#18694** â€“ ä¿®å¤å·²å®Œæˆè¯·æ±‚åœ¨æŠ¢å é˜¶æ®µçš„åŒé‡é‡Šæ”¾ KV ç¼“å­˜å¯¼è‡´çš„å´©æºƒã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sglang/srt/managers/schedule_policy.py`ï¼ˆåœ¨ `preempt_to_schedule` ä¸­åŠ å…¥ `and not r.finished()` è¿‡æ»¤ï¼‰  
  - `test/registered/scheduler/test_prefill_adder.py` ä¸­ä¸º Mock è¯·æ±‚æ·»åŠ  `req.finished.return_value = False` ä»¥é…åˆæ–°é€»è¾‘ã€‚  
  - **Commit**: `191d354` â€“ https://github.com/sgl-project/sglang/commit/191d354f538f81ea383e536f3b4421ed441374d8  

- **#18779** â€“ è‡ªåŠ¨åŒæ­¥æ¨¡å‹åŠ è½½å™¨ï¼šä½¿ç”¨ `buffered_multi_thread_safetensors_weights_iterator` æ›¿ä»£åŸå¤šçº¿ç¨‹è¿­ä»£å™¨ï¼Œæé«˜æƒé‡è¯»å–æ•ˆç‡ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sglang/srt/model_loader/loader.py`ï¼ˆè°ƒç”¨æ–°å‡½æ•°ï¼‰  
  - `python/sglang/srt/model_loader/weight_utils.py` ä¸­å®ç° `buffered_multi_thread_safetensors_weights_iterator`ï¼ˆæ–°å¢ `collections`ã€`itertools` å¯¼å…¥ï¼‰ã€‚  
  - **Commit**: `008ea46` â€“ https://github.com/sgl-project/sglang/commit/008ea46af13e496240680932ad52c21b9e0589fb  

- **#18543** â€“ å°† GPTQâ€‘Marlin é‡æ‰“åŒ… kernel ç§»æ¤è‡³ JITï¼Œå®ç°è¿è¡Œæ—¶ç¼–è¯‘ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sglang/jit_kernel/csrc/gemm/marlin/gptq_marlin_repack.cuh`ï¼ˆæ–°å¢ CUDA å®ç°ï¼‰  
  - `python/sglang/jit_kernel/gptq_marlin_repack.py` ä¸å¯¹åº” benchmarkã€æµ‹è¯•æ–‡ä»¶ã€‚  
  - **Commit**: `0012d6a` â€“ https://github.com/sgl-project/sglang/commit/0012d6a4ebff8d87c5f9f99c295f85d3b69bf1e7  

- **#18728** â€“ Diffusion æ¨¡å—ä¸­ VAE å¹¶è¡Œè§£ç ä½¿ç”¨æ‰¹é‡ P2P æ“ä½œæå‡ååã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../parallel/wan_dist_utils.py`ï¼ˆæ–°å¢ `batched_p2p` è°ƒç”¨ï¼‰  
  - **Commit**: `3727340` â€“ https://github.com/sgl-project/sglang/commit/37273408ebcde2d16890dc93d4e613825fc22f95  

- **#18790** â€“ ä¿®æ­£ diffusion ä»£ç ä¸­çš„æ‹¼å†™é”™è¯¯ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../scale_residual_norm_scale_shift.py`ï¼ˆ`scale_residual_norm_scale_shift` æ‹¼å†™ä¿®æ­£ï¼‰  
  - **Commit**: `acc940d` â€“ https://github.com/sgl-project/sglang/commit/acc940d30217ea6ff67a278a2d894d136466aca2  

- **#18797** â€“ å°† `test_load_lora_from_tensor` ç§»åŠ¨è‡³ H100 CI ç¯å¢ƒï¼Œé¿å…ä½é… GPU å¤±æ•ˆã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`test/registered/rl/test_lora_load_from_tensor.py`ï¼ˆä»…ä¿®æ”¹ `skipif` æ¡ä»¶ï¼‰  
  - **Commit**: `9a32f8c` â€“ https://github.com/sgl-project/sglang/commit/9a32f8ccb97697dd0d6a87ba323fcd2169e3aed9  

- **#18462** â€“ WebUI ä¸­ä»»åŠ¡ç±»å‹æ£€æŸ¥é”™è¯¯ä¿®å¤ï¼Œé˜²æ­¢éæ³• `task_type` å¯¼è‡´å¼‚å¸¸ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../apps/webui/main.py`ï¼ˆåŠ å…¥ `assert` ä¸é”™è¯¯æç¤ºï¼‰  
  - **Commit**: `0763334` â€“ https://github.com/sgl-project/sglang/commit/07633349c9eddaead57365a45871723270414251  

- **#18598** â€“ æ–°å¢ LingV2_5 æ¨¡å‹æ”¯æŒåŠç›¸åº”æ··åˆæ³¨æ„åŠ›å®ç°ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../configs/bailing_hybrid.py`ï¼ˆæ¨¡å‹é…ç½®ï¼‰  
  - `python/sgl.../layers/attention/linear/lightning_attn.py`ï¼ˆæ–°å¢ LightningAttention å®ç°ï¼‰  
  - **Commit**: `d97eb11` â€“ https://github.com/sgl-project/sglang/commit/d97eb111a368f8f19d0d5aac9b89cdd2243daed3  

- **#17934** â€“ æ·»åŠ  JIT ç‰ˆ RotaryEmbedding kernelï¼Œå®ç°é«˜æ•ˆä½ç½®ç¼–ç ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../jit_kernel/csrc/elementwise/pos_enc.cuh`ï¼ˆCUDA å®ç°ï¼‰  
  - `python/sgl.../jit_kernel/pos_enc.py` ä¸å¯¹åº”å•å…ƒæµ‹è¯• `test_pos_enc.py`ã€‚  
  - **Commit**: `7d4ae05` â€“ https://github.com/sgl-project/sglang/commit/7d4ae057ec7327132daf9c838118412a34993e28  

- **#18450** â€“ å¼•å…¥ Release Lookup é¡µé¢ï¼Œæä¾›å†å²å‘å¸ƒç´¢å¼•ä¸å¿«é€Ÿæ£€ç´¢ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`docs/release_lookup/README.md`ã€`generate_index.py`ã€`index.html`ã€`release_index.json`ï¼ˆå…¨æ–°æ–‡æ¡£ä¸ç”Ÿæˆè„šæœ¬ï¼‰  
  - **Commit**: `bc2405e` â€“ https://github.com/sgl-project/sglang/commit/bc2405e6c18a47c6457d9834358c441c21d965bc  

- **#18765** â€“ è‡ªåŠ¨åŒæ­¥ `grok.py`ï¼Œåˆ é™¤å†—ä½™å¯¼å…¥ã€‚  
  - å…³é”®æ–‡ä»¶ï¼š`python/sgl.../models/grok.py`ï¼ˆåˆ é™¤ 8 è¡Œæœªä½¿ç”¨ä»£ç ï¼‰  
  - **Commit**: `c56a5ef` â€“ https://github.com/sgl-project/sglang/commit/c56a5efbaaf57208cd3d6b056af0d1a624b2cd99  

ï¼ˆå…¶ä½™ 30+ å°å¹…æ”¹åŠ¨çš„æäº¤å·²åœ¨ä¸Šè¿°åˆ—è¡¨ä¸­æ¦‚æ‹¬ï¼Œå‡å·²åŒæ­¥ç‰ˆæœ¬å·ã€æ–‡æ¡£æˆ–æµ‹è¯•æ–‡ä»¶ï¼Œè¯¦æƒ…å¯åœ¨å¯¹åº” commit é¡µé¢æŸ¥çœ‹ã€‚ï¼‰  

**Issues**  

- **#18819** â€“ *KeyError: 'ministral3'*ï¼šæœ€æ–° SGLang ä¸ Transformers 0.5.1 ä¸å…¼å®¹ï¼Œå¯¼è‡´ Ministral3 æ¨¡å‹åŠ è½½å¤±è´¥ã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18819  

- **#18818** â€“ FP8 KV ç¼“å­˜å°ºåº¦æœªé€šè¿‡ `--quantization-param-path` æ­£ç¡®ä¼ é€’è‡³ `set_kv_buffer`ï¼Œå¯¼è‡´é‡åŒ–è¯¯å·®ã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18818  

- **#18816** â€“ å»ºè®®åœ¨ CI ä¸­åŠ å…¥æ–‡æ¡£é“¾æ¥æ£€æŸ¥ï¼Œä»¥è‡ªåŠ¨æ•è·å¤±æ•ˆçš„å†…éƒ¨é“¾æ¥ã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18816  

- **#18812** â€“ åœ¨ ROCm ç¯å¢ƒä¸‹ï¼ŒRotaryEmbedding å›é€€è·¯å¾„ä»å°è¯•åŠ è½½ CUDA JIT æ¨¡å—ï¼Œç¼ºå°‘ `CUDA_HOME` å¯¼è‡´ CI å¤±è´¥ã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18812  

- **#18799** â€“ DeepSeek V3.2 åœ¨ PD åˆ†è§£æ¨¡å¼ä¸‹é¢„å¡«å……å·¥ä½œè¿›ç¨‹å´©æºƒï¼Œæ¶‰åŠ DeepGEMM æš–å¯åŠ¨é˜¶æ®µã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18799  

- **#18798** â€“ è¯·æ±‚ä¸º Kimi K2.5 æ·»åŠ è§†é¢‘è¾“å…¥æ”¯æŒã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18798  

- **#18794** â€“ è·Ÿè¸ª Qwen3â€‘Coderâ€‘480Bâ€‘A35B åœ¨ B200/GB200 ä¸Šçš„åŠŸèƒ½ä¸ç²¾åº¦æ”¯æŒæƒ…å†µã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18794  

- **#18792** â€“ Qwen3 MoE åŒæ‰¹æ¬¡é‡å  Warmup å¤±è´¥ï¼Œç–‘ä¼¼æ³¨æ„åŠ›å±‚å®ç°é”™è¯¯ã€‚  
  - **é“¾æ¥**: https://github.com/sgl-project/sglang/issues/18792
### vllm-project/vllm
## æäº¤æ¦‚è§ˆ

| SHAï¼ˆçŸ­ï¼‰ | ä½œè€… | å…³é”®æ”¹åŠ¨ | å…³è”æ–‡ä»¶ï¼ˆæ¨¡å—/æ–‡ä»¶ï¼‰ | å¤‡æ³¨ |
|---|---|---|---|---|
| `c027541` | Harry Huang | åœ¨ **Hybrid** æ¨¡å¼ä¸‹ä¸º mamba cache align å¼€å¯ spec decoding | `tests/v1/e2e/test_mamba_prefix_cache.py`ã€`vllm/model_executor/models/config.py` | ä»£ç ç‰‡æ®µç¼ºå¤±ï¼ˆpatch_truncatedï¼‰ï¼Œä»…æ˜¾ç¤ºå¢åˆ è¡Œæ•° |
| `fd267bc` | Ben Browning | ä¿®å¤ multiâ€‘turn GPTâ€‘OSS çš„ç»“æ„åŒ–è¾“å‡º | `tests/entrypoints/openai/test_gptoss_structural_tags_integration.py`ã€`tests/reasoning/test_gptoss_reasoning_parser.py`ã€`tests/v1/structured_output/test_gptoss_structural_tags.py`ã€`vllm/reasoning/gptoss_reasoning_parser.py` | è¯¦ç»†å®ç°æœªå±•ç¤º |
| `bfaa559` | Michael Goin | å›æ»š fused MoE IMA stride ä¿®å¤ï¼ˆä½¿ç”¨ int64ï¼‰ | `vllm/model_executor/layers/fused_moe/fused_moe.py` | ä»£ç æ”¹åŠ¨ 27 è¡Œå¢åˆ ï¼Œå…·ä½“å®ç°æœªå±•å¼€ |
| `87789c8` | Richard Zou | `--enforce-eager` ä»…å…³é—­ compile ä¸ cudagraphs | `vllm/config/vllm.py` | 7 è¡Œå¢åˆ  |
| `bcd65c1` | Pushpinder Singh | å°† topk kernel ä¸­çš„ `c10::optional` æ›¿æ¢ä¸º `std::optional` | `csrc/topk.cu` | 1 è¡Œæ”¹åŠ¨ |
| `59d5306` | Wei Zhao | æ”¯æŒ CPU Offloading æ—¶ä¸ä½¿ç”¨ PyTorch pinned memoryï¼Œé™ä½å†…å­˜å ç”¨ | `csrc/cuda_view.cu`ã€`tests/basic_correctness/test_cpu_offload.py`ã€`vllm/envs.py`ã€`vllm/model_executor/model_loader/utils.py`ã€`vllm/model_executor/models/utils.py`ã€`vllm/utils/torch_utils.py` | å…³é”®æ€§èƒ½æ”¹è¿›ï¼Œæ–°å¢ 129 è¡Œä»£ç  |
| `4a9952e` | LoganJane | ä¸º Kimiâ€‘K2.5 çš„ ViT æ·»åŠ  `quant_config` | `vllm/model_executor/models/kimi_k25.py`ã€`vllm/model_executor/models/kimi_k25_vit.py` | 26 è¡Œæ–°å¢ |
| `1dae7b7` | Roger Wang | åœ¨ MM AOT ç¼–è¯‘å“ˆå¸Œä¸­æ’é™¤ `language_model_only` é”®ï¼Œä½†åœ¨æ¨¡å‹å“ˆå¸Œä¸­ä¿ç•™ | `tests/config/test_multimodal_config.py`ã€`vllm/config/model.py`ã€`vllm/config/multimodal.py` | ä»… 1 è¡Œåˆ é™¤ |
| `5885e33` | Roger Wang | ç§»æ¤ Qwen3.5 é…ç½®æ–‡ä»¶ | `vllm/model_executor/models/qwen3_5.py`ã€`vllm/model_executor/models/qwen3_5_mtp.py`ã€`vllm/transformers_utils/config.py`ã€`vllm/transformers_utils/configs/__init__.py`ã€`vllm/transformers_utils/configs/qwen3_5.py`ï¼ˆæ–°å¢ï¼‰ ã€`vllm/transformers_utils/configs/qwen3_5_moe.py`ï¼ˆæ–°å¢ï¼‰ | æ–°å¢ 410 è¡Œé…ç½® |
| `071d863` | Ilya Boytsov | æ‰©å±• ColBERT å¯¹éæ ‡å‡† BERT éª¨å¹²çš„æ”¯æŒ | `docs/models/pooling_models.md`ã€`examples/pooling/score/colbert_rerank_online.py`ã€`tests/entrypoints/pooling/score/test_online_colbert.py`ã€`tests/models/language/pooling/test_colbert.py`ã€`tests/models/registry.py`ã€`vllm/model_executor/models/colbert.py`ã€`vllm/model_executor/models/config.py`ã€`vllm/model_executor/models/registry.py`ã€`vllm/transformers_utils/config.py` | ä»£ç æ”¹åŠ¨ç´¯è®¡ 1â€¯102 è¡Œ |
| `0916e79` | Woosuk Kwon | ä½¿ç”¨ CPU å¼ é‡æ„å»º GDN å…ƒæ•°æ® | `vllm/v1/attention/backends/gdn_attn.py`ã€`vllm/v1/attention/backends/utils.py` | 12 è¡Œæ–°å¢ |
| `3d2a026` | Wentao Ye | Pipeline Parallel å¼‚æ­¥ send/recvï¼Œæå‡ 2.9% E2E åå | `tests/distributed/test_comm_ops.py`ã€`vllm/distributed/parallel_state.py`ã€`vllm/v1/worker/gpu_worker.py` | 298 è¡Œæ–°å¢ï¼Œ81 è¡Œåˆ é™¤ |
| `dddbff4` | Aaron Hao | å°† pause / resume åŠŸèƒ½è¿å…¥ engine å±‚ | `examples/online_serving/data_parallel_pause_resume.py`ï¼ˆæ–°å¢ï¼‰ ã€`tests/v1/distributed/test_async_llm_dp.py`ã€`tests/v1/engine/test_async_llm.py`ã€`tests/v1/engine/test_engine_core_client.py`ã€`vllm/v1/core/sched/interface.py`ã€`vllm/v1/core/sched/scheduler.py`ã€`vllm/v1/engine/async_llm.py`ã€`vllm/v1/engine/core.py`ã€`vllm/v1/engine/core_client.py` | 621 è¡Œæ–°å¢ï¼Œ136 è¡Œåˆ é™¤ |
| `47e9b63` | Martin Hickey | æ¸…ç† KV connector å†—ä½™ä»£ç  | `vllm/distributed/kv_transfer/kv_connector/v1/__init__.py`ã€`vllm/distributed/kv_transfer/kv_connector/v1/example_connector.py`ã€`vllm/distributed/kv_transfer/kv_connector/v1/lmcache_mp_connector.py`ã€`vllm/distributed/kv_transfer/kv_connector/v1/offloading_connector.py` | ä»… 2 è¡Œæ–°å¢ |
| `934acdd` | Matthias Gehre | ä¸º fused_moe æ·»åŠ  int4_w4a16 åŸºå‡†æ”¯æŒåŠè°ƒä¼˜é…ç½® | `benchmarks/kernels/benchmark_moe.py`ã€`vllm/model_executor/layers/fused_moe/configs/E=128,N=768,device_name=Radeon_8060S_Graphics,dtype=int4_w4a16.json`ï¼ˆæ–°å¢ï¼‰ | 185 è¡Œæ–°å¢ |
| `742d214` | Marek Michalowski | ä¿®å¤ MoE æµ‹è¯• utils çš„å¯¼å…¥è·¯å¾„ | `tests/kernels/moe/utils.py` | 5 è¡Œå¢åˆ  |
| `4137c5d` | haosdent | ä¿®å¤ MambaManager åœ¨ align æ¨¡å¼ä¸‹å¯¹ç©ºå—çš„å´©æºƒ | `tests/v1/core/test_prefix_caching.py`ã€`vllm/v1/core/single_type_kv_cache_manager.py` | 48 è¡Œæ–°å¢ |
| `7a8a46d` | Harry Huang | ä¼˜åŒ– MambaSpec ä¸­ `max_num_blocks_per_req` çš„è®¡ç®— | `vllm/v1/worker/gpu_model_runner.py` | 17 è¡Œæ”¹åŠ¨ |
| `bcf0731` | myselvess | æ–°å¢å¯¹ ovis2.6 æ¨¡å‹çš„æ”¯æŒ | `docs/models/supported_models.md`ã€`tests/models/registry.py`ã€`vllm/model_executor/models/ovis2_5.py`ã€`vllm/model_executor/models/registry.py`ã€`vllm/model_executor/models/siglip2navit.py`ã€`vllm/transformers_utils/processors/ovis2_5.py` | 52 è¡Œæ–°å¢ |
| `ec090c2` | Cyrus Leung | åœ¨åœ¨çº¿ IO å¤„ç†å™¨è¯·æ±‚ä¸­è°ƒç”¨æ¸²æŸ“å™¨ | `vllm/entrypoints/llm.py`ã€`vllm/entrypoints/openai/engine/serving.py`ã€`vllm/entrypoints/pooling/pooling/protocol.py`ã€`vllm/entrypoints/pooling/pooling/serving.py` | 39 è¡Œæ–°å¢ |
| `eea3024` | Roger Wang | ä¸º Qwen3â€‘Next / Qwen3.5 ä¿®æ­£ mamba çŠ¶æ€ dtype è®¾ç½® | `vllm/model_executor/layers/mamba/mamba_utils.py`ã€`vllm/model_executor/models/config.py`ã€`vllm/model_executor/models/qwen3_5.py`ã€`vllm/model_executor/models/qwen3_next.py` | 42 è¡Œæ–°å¢ |
| `2f30821` | Cyrus Leung | å°†å®Œæ•´çš„ `VllmConfig` ä¼ é€’ç»™æ¸²æŸ“å™¨ | å¤šä¸ªæµ‹è¯•æ–‡ä»¶ä¸æ¸²æŸ“å™¨å®ç°ï¼ˆå…± 137 è¡Œæ–°å¢ï¼Œ86 è¡Œåˆ é™¤ï¼‰ | è¯¦ç»†æ”¹åŠ¨åœ¨å¤šä¸ªæ–‡ä»¶ä¸­ï¼Œpatch å·²æˆªæ–­ |
| `1b4e8e5` | Cyrus Leung | ä¿®å¤åˆ†å¸ƒå¼æ¨¡å‹æµ‹è¯•ä¸­ CUDA é‡åˆå§‹åŒ–é”™è¯¯ | `tests/models/multimodal/generation/test_voxtral_realtime.py` | 3 è¡Œæ–°å¢ |
| `dcf6ee8` | haosdent | ä¿®æ­£ GLMâ€‘4V/GLMâ€‘OCR å•å›¾åƒçš„ encoder cache ä½ä¼° | `vllm/model_executor/models/glm4_1v.py` | 22 è¡Œæ–°å¢ |
| `372b2e7` | Cyrus Leung | æ ‡å‡†åŒ–è·å–å›¾åƒ patch / token æ•°é‡çš„æ–¹å¼ | å¤šä¸ª multimodal æµ‹è¯•ä¸æ¨¡å‹æ–‡ä»¶ï¼ˆç´¯è®¡ 320 è¡Œæ–°å¢ï¼Œ332 è¡Œåˆ é™¤ï¼‰ | ä»£ç é‡å¤§ï¼Œpatch å·²æˆªæ–­ |
| `6afa587` | Andreas Karatzas | ä¿®å¤ ROCm CI ä¸­ servingâ€‘tokens æµ‹è¯•å¤±è´¥ | `tests/entrypoints/openai/test_serving_tokens.py` | 28 è¡Œæ–°å¢ |
| `94ed6cf` | Cyrus Leung | ä¸º CODEOWNERS æ·»åŠ æ–°ç« èŠ‚ | `.github/CODEOWNERS` | 27 è¡Œæ–°å¢ |
| `bf37812` | Harry Huang | ä¼˜åŒ– mamba cache align æ¨¡å¼ä¸‹çš„å—å¯¹é½æ‹†åˆ† | `vllm/v1/core/sched/scheduler.py` | 14 è¡Œæ–°å¢ |
| `b86bf44` | Frank Wang | ä¿®å¤éšæœºæ•°æ®é›†å‰ç¼€é•¿åº¦ç»Ÿè®¡ä¸å‡†ç¡®çš„é—®é¢˜ | `vllm/benchmarks/datasets.py` | 29 è¡Œæ–°å¢ |
| `de13dd7` | Yanan Cao | å¼•å…¥ Helion è‡ªåŠ¨è°ƒä¼˜åŸºç¡€è®¾æ–½ï¼ˆ5/5ï¼‰ | `scripts/autotune_helion_kernels.py`ï¼ˆæ–°å¢ 430 è¡Œï¼‰ ã€`vllm/kernels/helion/config_manager.py`ã€`vllm/kernels/helion/register.py` | 551 è¡Œæ–°å¢ |
| `62788f9` | LoganJane | åˆ é™¤ Kimiâ€‘K2.5 ä¸­æœªä½¿ç”¨çš„å†—ä½™ä»£ç  | `vllm/model_executor/models/kimi_k25.py` | 5 è¡Œåˆ é™¤ |
| `ea5ff3a` | Cyrus Leung | ç®€åŒ– BOS/EOS token å¤„ç†é€»è¾‘ | å¤šä¸ªæµ‹è¯•ä¸æ ¸å¿ƒæ–‡ä»¶ï¼ˆå…± 123 è¡Œå¢åˆ ï¼‰ | ä»£ç æ”¹åŠ¨å‡ä¸º 1 è¡Œå¢åˆ  |

> **è¯´æ˜**ï¼šå¤šæ•°æäº¤çš„ `patch` è¢«æ ‡è®°ä¸º `patch_truncated`ï¼Œå› æ­¤è¿™é‡Œåªåˆ—å‡ºæ–‡ä»¶è·¯å¾„ã€å¢åˆ è¡Œæ•°ä»¥åŠæ”¹åŠ¨æ¦‚è¦ï¼Œæœªèƒ½å±•ç¤ºå…·ä½“ä»£ç ç‰‡æ®µã€‚

## Issue æ‘˜è¦

| ç¼–å· | æ ‡é¢˜ | ä½œè€… | ç®€è¦æè¿° |
|---|---|---|---|
| #34536 | **Reasoning output for offline inference** | BartekKruczek | è¯¢é—®æ˜¯å¦åœ¨ç¦»çº¿æ¨ç†æ—¶ç›´æ¥æ”¯æŒç»“æ„åŒ–æ¨ç†è¾“å‡ºï¼Œä»¥å…æ‰‹åŠ¨è§£æä¸Šä¸‹æ–‡ã€‚ |
| #34534 | **EngineCore exits immediately after startup when vLLM CPU is launched from multiprocessing.Process on macOS** | diegocastanibm | åœ¨ macOS Apple Silicon ä¸Šï¼Œä½¿ç”¨ `multiprocessing.Process` å¯åŠ¨ CPU ç‰ˆ vLLM æ—¶ï¼ŒEngineCore ç«‹å³é€€å‡ºã€‚ |
| #34532 | **Realtime API crashes when client terminates connection "incorrectly"** | nullquery | å®æ—¶ API åœ¨å®¢æˆ·ç«¯å¼‚å¸¸æ–­å¼€åå´©æºƒï¼Œæ¶‰åŠ Voxtral Mini 4B 2602 çš„ç”Ÿäº§çº§ä½¿ç”¨åœºæ™¯ã€‚ |
| #34526 | **accuracy issue when using multiconnector (Nixl+cpu offloading)** | hsubramony | å¤šè¿æ¥å™¨ï¼ˆNixl + CPU offloadingï¼‰å¯¼è‡´æ¨ç†ç²¾åº¦ä¸‹é™ã€‚ |
| #34525 | **CI Failure: LoRA TP (Distributed) â€“ test_olmoe_lora** | LucasWilkinson | CI ä¸­ LoRA TP åˆ†å¸ƒå¼æµ‹è¯• `test_olmoe_lora` å¤±è´¥ã€‚ |
| #34524 | **Error saving sharded state for GPTâ€‘OSSâ€‘120B â€“ safetensors KeyError for torch.float8_e8m0fnu** | dhayanesh | ä¿å­˜ GPTâ€‘OSSâ€‘120B åˆ†ç‰‡çŠ¶æ€æ—¶å‡ºç° `KeyError`ï¼Œæ¶‰åŠ `torch.float8_e8m0fnu`ã€‚ |
| #34519 | **Quality of life â€“ expose model name / custom label in GPU process name** | Rictus | å»ºè®®åœ¨ GPU è¿›ç¨‹åç§°ä¸­æ˜¾ç¤ºæ¨¡å‹åç§°æˆ–è‡ªå®šä¹‰æ ‡ç­¾ï¼Œä»¥æå‡å¯è§‚æµ‹æ€§ã€‚ |
| #34518 | **[Whisper] Support for decoder prefix and custom task tokens in transcription API** | LouisChirol | è¯·æ±‚åœ¨ Whisper è½¬å½• API ä¸­åŠ å…¥è§£ç å™¨å‰ç¼€å’Œè‡ªå®šä¹‰ä»»åŠ¡æ ‡è®°çš„æ”¯æŒã€‚ |
| #34525 (duplicate) | **CI Failure** | â€” | å¦æœ‰ CI ç›¸å…³é—®é¢˜ï¼Œè¯¦æƒ…ç¼ºå¤±ã€‚ |

> **è¯´æ˜**ï¼šéƒ¨åˆ† Issue çš„æ­£æ–‡è¢«æˆªæ–­ï¼ˆ`body_truncated: true`ï¼‰ï¼Œå› æ­¤ä»…æä¾›æ ‡é¢˜ã€ä½œè€…åŠå·²çŸ¥çš„ç®€è¦éœ€æ±‚æˆ–é”™è¯¯æè¿°ã€‚
### NVIDIA/cutile-python
**æäº¤**  
- **394d302** â€“ Jayâ€¯Gu, 2026â€‘02â€‘11  
  *Create temp dir if not exist*  
  - **PR**ï¼šæ— ï¼ˆä»…æä¾› commit SHAï¼‰  
  - **Commit URL**ï¼š<https://github.com/NVIDIA/cutile-python/commit/394d302ae6b31f988cb91d80b466c6a695405a43>  
  - **å˜æ›´æ–‡ä»¶**  
    - `src/cuda/tile/_compile.py` (ä¿®æ”¹) â€“ +2 / â€“2 è¡Œ  
      - Diff æœªæä¾›ï¼Œpatch è¢«æˆªæ–­ã€‚  
    - `src/cuda/tile/_context.py` (ä¿®æ”¹) â€“ +2 / â€“0 è¡Œ  
      - Diff æœªæä¾›ï¼Œpatch è¢«æˆªæ–­ã€‚  

**Issues**  
- æ— ã€‚

## æ€»ç»“
âš¡ **è¶‹åŠ¿**ï¼šFP8 ä¸ SM120 ç›¸å…³ç®—å­å¿«é€Ÿè½åœ°ï¼Œè¡¨æ˜ä¸šç•Œæ­£åŠ é€Ÿå‘æ›´é«˜ååçš„æ··åˆç²¾åº¦æ¨ç†è¿ç§»ï¼›å¤šçº¿ç¨‹/å¤šè¿›ç¨‹æ¨¡å‹åŠ è½½ä¸ Pipeline Parallel çš„ä¼˜åŒ–ï¼Œé¢„ç¤ºå¤§æ¨¡å‹éƒ¨ç½²çš„èµ„æºåˆ©ç”¨ç‡å°†è¿›ä¸€æ­¥æå‡ã€‚ğŸ”§ **å…³æ³¨ç‚¹**ï¼šå¤šä¸ªä»“åº“ä»æœ‰å…³é”® Issue å¾…è§£å†³ï¼Œå¦‚ Cutlass çš„åŠ¨æ€å¸ƒå±€æ¨æ–­ã€FlashInfer çš„ SM120 gatingã€sglang çš„ FP8 KV ç¼“å†²ä¼ é€’ä»¥åŠ vllm çš„ CPU offload å†…å­˜å ç”¨ã€‚å»ºè®®å…³æ³¨è¿™äº›é˜»å¡é—®é¢˜çš„è¿›å±•ï¼Œä»¥å…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­å‡ºç°å…¼å®¹æ€§æˆ–æ€§èƒ½å›é€€ã€‚
