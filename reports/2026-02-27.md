今日的 AI Infra 的新闻如下。

## 摘要
本周 **NVIDIA/cutlass** 通过多次合并（如 #3028、#3079）完成了文档、示例以及底层实现的细节修正，重点解决了 `import cutlass` 在仅 CPU 环境下崩溃以及 TiledMMA 在不同 JIT 函数中的状态冲突等关键 BUG；**flash-attention** 在 SM100 架构上实现了 2CTA 前向/后向路径、管线调度改进以及对 `mma_tile_coord_v` 的支持，显著提升了 hdim128 场景的吞吐；**sglang** 继续深化 AMD 与 NPU 适配，推出了全新 **dump comparator** 框架、Diffusion 插件以及多模态 TensorData 解析，配合大量单元测试提升了代码可靠性；**vllm** 引入 Model Runner V2 接口、支持自定义数据集的 Base64 图像、以及 MXFP4 量化插件，同时清理了 BNB 相关残余代码并在 CI 中加入了多平台（AMD、ROCm、MORIIO）验证；**flashinfer** 关注编译兼容性（sm120f）和 AllReduceFusion 多组分布式支持；**DeepGEMM** 仍在讨论尺度因子布局的实现细节。

## 具体内容分析
### deepseek-ai/DeepGEMM
Issues：
- Question about the scale factor layout (https://github.com/deepseek-ai/DeepGEMM/issues/289)
### deepseek-ai/FlashMLA
昨日无更新。
### NVIDIA/cutlass
提交：
- Merge pull request #3028 from SzymonOzog/patch-3 [`b984769`](https://github.com/NVIDIA/cutlass/commit/b9847690c5838ac3d909ebc163ed16c388802485)
- 受影响文件: python/CuTeDSL/cutlass/cute/core.py
- v4.4.1 update (#3079) [`3bb6e28`](https://github.com/NVIDIA/cutlass/commit/3bb6e28d3c9cfab1f01093563a404229dc658de1)
- 受影响文件: CHANGELOG.md, README.md, examples/python/CuTeDSL/hopper/cta_norm.py, include/cutlass/gemm/collective/sm90_mma_array_tma_gmma_ss_warpspecialized_fp8_blockwise_scaling.hpp, include/cutlass/version.h, python/CuTeDSL/cutlass/base_dsl/tvm_ffi_builder/mlir_builder.py, python/CuTeDSL/cutlass/cutlass_dsl/tvm_ffi_provider.py, python/CuTeDSL/requirements-cu13.txt, python/CuTeDSL/requirements.txt, python/cutlass_cppgen/__init__.py, python/setup_cutlass.py, python/setup_library.py, python/setup_pycute.py
- fix typo (#3012) [`c651d66`](https://github.com/NVIDIA/cutlass/commit/c651d660d22bed49ffc1330feeb3e02a9f0a6b2c)
- 受影响文件: examples/cute/tutorial/blackwell/04_mma_tma_2sm_sm100.cu, examples/cute/tutorial/blackwell/05_mma_tma_epi_sm100.cu
- Fix error in Blackwell document of referring to Mxf4 format as NVF4 (#2977) [`518327d`](https://github.com/NVIDIA/cutlass/commit/518327d6317756f02cacdc0433d48ac57d328e99)
- 受影响文件: media/docs/cpp/blackwell_functionality.md
- Fix example in CuTe tutorials (#2752) [`de67bb7`](https://github.com/NVIDIA/cutlass/commit/de67bb7a42f8bb6dbe898df5c4e3a0f3b0551aac)
- 受影响文件: media/docs/cpp/cute/02_layout_algebra.md
- Fix register index bug in mma.sync.aligned.m16n8k16 (#2740) [`edf2f82`](https://github.com/NVIDIA/cutlass/commit/edf2f82c0025b98b48977cb83db746769721b4ee)
- 受影响文件: include/cutlass/arch/mma_sm90.h
- Fix debug typo in sgemm_2.cu and sgemm_sm70.cu (#2678) [`7934535`](https://github.com/NVIDIA/cutlass/commit/79345359a790c18893f8368c4493d33d9ed314c5)
- 受影响文件: examples/cute/tutorial/sgemm_2.cu, examples/cute/tutorial/sgemm_sm70.cu
- fix typo in documentation (#2671) [`8b9b3d7`](https://github.com/NVIDIA/cutlass/commit/8b9b3d78dfedc707e92b00dd0c9007238d4e597c)
- 受影响文件: tools/util/include/cutlass/util/host_tensor_planar_complex.h
- Fix typo in cute.nvgpu.warpgroup.mma doc (#2548) [`fc5bbc2`](https://github.com/NVIDIA/cutlass/commit/fc5bbc2dabadb80ff30fa7e5bb3318ac1a017d2f)
- 受影响文件: python/CuTeDSL/cutlass/cute/nvgpu/warpgroup/mma.py
Issues：
- [BUG] `import cutlass` crashes on CPU-only machines when jax is installed (v4.4 regression) (https://github.com/NVIDIA/cutlass/issues/3083)
- Issue 内容已截断。
- [FEA] will cuteDSL support INT8 GEMM and FP8 GEMM on Ada/Ampere platform (https://github.com/NVIDIA/cutlass/issues/3081)
- [QST] TiledMMA.make_fragment_A fails with non-swizzled smem layout (https://github.com/NVIDIA/cutlass/issues/3078)
- Issue 内容已截断。
- [BUG] TiledMMA modifier can't be set in different jit function (https://github.com/NVIDIA/cutlass/issues/3077)
- Issue 内容已截断。
### flashinfer-ai/flashinfer
提交：
- chore: Update CODEOWNERS (#2286) [`f521fe1`](https://github.com/flashinfer-ai/flashinfer/commit/f521fe19ac387e8baffd7b5c925ef59d9f2ecc0c)
- 受影响文件: .github/CODEOWNERS
- fix: trtllm_mxint4_block_scale_moe unit test to index output list (#2627) [`a337e42`](https://github.com/flashinfer-ai/flashinfer/commit/a337e42e6ae91f512ff066bc09180a1ffa74ba88)
- 受影响文件: tests/moe/test_trtllm_gen_fused_moe.py
Issues：
- Enable compilation for sm120f for DGX Spark, RTX Pro 6000, etc. (https://github.com/flashinfer-ai/flashinfer/issues/2649)
- [BUG] AllReduceFusion doesn't support multiple distributed groups (https://github.com/flashinfer-ai/flashinfer/issues/2647)
### Dao-AILab/flash-attention
提交：
- Bump to 4.4.1 to avoid segfault (#2291) [`7ed0898`](https://github.com/Dao-AILab/flash-attention/commit/7ed0898caa50a8f3fbb4f7212a437479bd59dfc1)
- 受影响文件: flash_attn/cute/pyproject.toml
- [Fwd,Sm100] Enable 2CTA for hdim128 noncausal [`9aadb8b`](https://github.com/Dao-AILab/flash-attention/commit/9aadb8bdc609775e6a8991c79ef47ac9f7944c3e)
- 受影响文件: flash_attn/cute/flash_fwd_sm100.py, flash_attn/cute/interface.py, flash_attn/cute/tile_scheduler.py
- [Fwd,Sm100] Add pipeline.producer_tail [`b936061`](https://github.com/Dao-AILab/flash-attention/commit/b936061f497beb2ccdd7869b429ed93476975f3f)
- 受影响文件: flash_attn/cute/flash_fwd_sm100.py
- [Fwd,Sm100] Take into account mma_tile_coord_v when reading/writing [`a631802`](https://github.com/Dao-AILab/flash-attention/commit/a6318026082554363f9b019bccf45afd0a1e8696)
- 受影响文件: flash_attn/cute/flash_fwd_sm100.py
- [Fwd,Sm100] Gate mma with is_leader_cta [`58d0c57`](https://github.com/Dao-AILab/flash-attention/commit/58d0c57c689b0aa6015ad4d227054670881c9f19)
- 受影响文件: flash_attn/cute/flash_fwd_sm100.py
- [Fwd,Sm100] Pass cta_layout_vmnk to pipelines [`d1d3e8d`](https://github.com/Dao-AILab/flash-attention/commit/d1d3e8dc3554df8112f2c14e8f3e2fa3e3cb25d6)
- 受影响文件: flash_attn/cute/flash_fwd_sm100.py
- [Fwd,Sm100] Change layout of gQ and gO to have q_stage [`01bc8ef`](https://github.com/Dao-AILab/flash-attention/commit/01bc8ef60d3237395743bb6e807200f27df9af6d)
- 受影响文件: flash_attn/cute/block_sparse_utils.py, flash_attn/cute/flash_fwd_sm100.py
- [Cute,Sm100,Bwd] Fix and enable 2CTA path for hdim 128 backward (#2280) [`a00ddeb`](https://github.com/Dao-AILab/flash-attention/commit/a00ddeb2b8f8a68b2e03b7bee5980e819069cdd1)
- 受影响文件: flash_attn/cute/flash_bwd_sm100.py, flash_attn/cute/interface.py
Issues：
- CPU-side Segfault for FA4 (https://github.com/Dao-AILab/flash-attention/issues/2281)
- Issue 内容已截断。
### sgl-project/sglang
提交：
- [AMD] MORI-EP support for EP4. (#19578) [`8240a87`](https://github.com/sgl-project/sglang/commit/8240a8730624c627e7908534c00666039bf50624)
- 受影响文件: docker/rocm.Dockerfile, python/sglang/srt/layers/moe/token_dispatcher/moriep.py
- [AMD] Remove Redundant tvm-ffi Installation in amd_ci_install_dependency.sh (#19554) [`560b867`](https://github.com/sgl-project/sglang/commit/560b867ccea9f03bdf754591e17f8c1d214a22eb)
- 受影响文件: scripts/ci/amd/amd_ci_install_dependency.sh
- [Fix] Add --disable-draft-model-update to control draft model updates(especially in RL) (#15726) [`f451664`](https://github.com/sgl-project/sglang/commit/f4516645041137d4ee826fdda7efc05b8fba4819)
- 受影响文件: python/sglang/srt/managers/io_struct.py, python/sglang/srt/managers/scheduler_update_weights_mixin.py
- [Anthropic API] Preserve image content in `tool_result` conversion (#19233) [`9c81ce4`](https://github.com/sgl-project/sglang/commit/9c81ce4707927c5a18cbac82dd70c3769ad269be)
- 受影响文件: python/sglang/srt/entrypoints/anthropic/serving.py, test/registered/openai_server/basic/test_anthropic_server.py
- [RadixTree][6/N Refactor]: Refactor SWARadixTree to simplify the computation and alignment of bigram keys. (#19427) [`a0d8a7a`](https://github.com/sgl-project/sglang/commit/a0d8a7ae6dd23001a05da073424703c579444cf0)
- 受影响文件: python/sglang/srt/mem_cache/radix_cache.py, python/sglang/srt/mem_cache/swa_radix_cache.py, test/registered/radix_cache/test_swa_unittest.py
- Support singleton dimension squeezing in dump comparator (#19566) [`5705e02`](https://github.com/sgl-project/sglang/commit/5705e02d286e59863b54935a415735f173e29361)
- 受影响文件: python/sglang/srt/debug_utils/comparator/aligner/axis_aligner.py, python/sglang/srt/debug_utils/comparator/aligner/entrypoint/executor.py, python/sglang/srt/debug_utils/comparator/aligner/entrypoint/planner.py, python/sglang/srt/debug_utils/comparator/aligner/entrypoint/types.py, python/sglang/srt/debug_utils/comparator/aligner/token_aligner/aux_loader.py, python/sglang/srt/debug_utils/comparator/bundle_comparator.py, python/sglang/srt/debug_utils/comparator/dims.py, python/sglang/srt/debug_utils/comparator/output_types.py, test/registered/debug_utils/comparator/aligner/test_axis_aligner.py, test/registered/debug_utils/comparator/aligner/unsharder/test_executor.py, test/registered/debug_utils/comparator/test_dims.py, test/registered/debug_utils/comparator/test_entrypoint.py, test/registered/debug_utils/comparator/test_model_validation.py, test/registered/debug_utils/source_patcher/test_code_patcher.py, test/registered/debug_utils/source_patcher/test_dumper_integration.py, test/registered/debug_utils/source_patcher/test_source_editor.py
- Visualize comparison detailed results in dump comparator (#19565) [`80bbd30`](https://github.com/sgl-project/sglang/commit/80bbd30909becc3f009771e59642af1f45eb6d72)
- 受影响文件: python/sglang/srt/debug_utils/comparator/bundle_comparator.py, python/sglang/srt/debug_utils/comparator/entrypoint.py, python/sglang/srt/debug_utils/comparator/visualizer/__init__.py, python/sglang/srt/debug_utils/comparator/visualizer/figure.py, python/sglang/srt/debug_utils/comparator/visualizer/panels.py, python/sglang/srt/debug_utils/comparator/visualizer/preprocessing.py, python/sglang/srt/debug_utils/dump_loader.py, test/registered/debug_utils/comparator/aligner/unsharder/test_executor.py, test/registered/debug_utils/comparator/test_entrypoint.py, test/registered/debug_utils/comparator/test_manually_verify.py, test/registered/debug_utils/comparator/test_visualizer.py
- Handle recompute and verify closeness in dumper (#19564) [`40facdb`](https://github.com/sgl-project/sglang/commit/40facdb28c4bd2c7aa3a02d3fa3c5fdbd55e8afe)
- 受影响文件: python/sglang/srt/debug_utils/comparator/aligner/unsharder/parallel_info.py, python/sglang/srt/debug_utils/comparator/dims.py, python/sglang/srt/debug_utils/comparator/entrypoint.py, python/sglang/srt/debug_utils/dump_loader.py, python/sglang/srt/debug_utils/dumper.py, test/registered/debug_utils/comparator/aligner/unsharder/test_executor.py, test/registered/debug_utils/comparator/aligner/unsharder/test_parallel_info.py, test/registered/debug_utils/comparator/aligner/unsharder/test_planner.py, test/registered/debug_utils/comparator/test_entrypoint.py, test/registered/debug_utils/test_dump_loader.py, test/registered/debug_utils/test_dumper.py
- Support non-intrusive arbitrary dumping in dumper and add e2e tests (#19563) [`63a4778`](https://github.com/sgl-project/sglang/commit/63a4778542c2b7e6e91af8a43d284c71bb650305)
- 受影响文件: python/sglang/srt/debug_utils/dumper.py, python/sglang/srt/model_executor/model_runner.py, test/registered/debug_utils/source_patcher/test_dumper_integration.py, test/registered/debug_utils/test_dumper.py, test/registered/debug_utils/test_engine_dumper_comparator_e2e.py
- Update layer id extraction, diffing, empty handling and error sentinel in dump comparator (#19562) [`ccbc47d`](https://github.com/sgl-project/sglang/commit/ccbc47d6be44ecdebb4ee3d15eaf4b11e1c63623)
- 受影响文件: python/sglang/srt/debug_utils/comparator/aligner/unsharder/parallel_info.py, python/sglang/srt/debug_utils/comparator/aligner/unsharder/planner.py, python/sglang/srt/debug_utils/comparator/tensor_comparator/comparator.py, python/sglang/srt/debug_utils/comparator/tensor_comparator/formatter.py, python/sglang/srt/debug_utils/dump_comparator.py
- Support patching source code (#19561) [`4097eb5`](https://github.com/sgl-project/sglang/commit/4097eb5ce964b2f3e70b08fd5edb66beade58967)
- 受影响文件: python/sglang/srt/debug_utils/source_patcher/__init__.py, python/sglang/srt/debug_utils/source_patcher/code_patcher.py, python/sglang/srt/debug_utils/source_patcher/source_editor.py, python/sglang/srt/debug_utils/source_patcher/types.py, test/registered/debug_utils/source_patcher/conftest.py, test/registered/debug_utils/source_patcher/test_code_patcher.py, test/registered/debug_utils/source_patcher/test_source_editor.py
- Enhance metrics in dump comparator (#19560) [`b73aa53`](https://github.com/sgl-project/sglang/commit/b73aa53d7e9ded56a0359004c107c195bb7bebe2)
- 受影响文件: python/sglang/srt/debug_utils/comparator/tensor_comparator/comparator.py, python/sglang/srt/debug_utils/comparator/tensor_comparator/formatter.py, python/sglang/srt/debug_utils/comparator/tensor_comparator/types.py, test/registered/debug_utils/comparator/tensor_comparator/test_comparator.py, test/registered/debug_utils/comparator/tensor_comparator/test_formatter.py, test/registered/debug_utils/comparator/tensor_comparator/test_types.py, test/registered/debug_utils/comparator/test_model_validation.py
- Support method decorator for tagging and add minimalistic comparator in dumper (#19559) [`706ab92`](https://github.com/sgl-project/sglang/commit/706ab9296afbbba14c891ab722f6894f92f509c7)
- 受影响文件: python/sglang/srt/debug_utils/dump_comparator.py, python/sglang/srt/debug_utils/dumper.py, test/registered/debug_utils/comparator/test_entrypoint.py, test/registered/debug_utils/comparator/test_model_validation.py, test/registered/debug_utils/test_dump_comparator.py, test/registered/debug_utils/test_dumper.py
- Support handling arbitrary objects in dump comparator (#19558) [`9bf3638`](https://github.com/sgl-project/sglang/commit/9bf3638a259cbe46c106b83b1fcbec4677a60b50)
- 受影响文件: python/sglang/srt/debug_utils/comparator/bundle_comparator.py, python/sglang/srt/debug_utils/comparator/display.py, python/sglang/srt/debug_utils/comparator/entrypoint.py, python/sglang/srt/debug_utils/comparator/output_types.py, python/sglang/srt/debug_utils/dump_loader.py, test/registered/debug_utils/comparator/test_entrypoint.py, test/registered/debug_utils/comparator/test_model_validation.py
- [NPU] bugs fix for Deepseek models (#19544) [`b7f13a7`](https://github.com/sgl-project/sglang/commit/b7f13a7b7328d9092ffdc78597e6dc1b189db9b4)
- 受影响文件: python/sglang/srt/hardware_backend/npu/attention/mla_preprocess.py, python/sglang/srt/managers/schedule_policy.py
- [NPU]Optimize the PR pipeline to reduce E2E runtime (#18767) [`1eb40d8`](https://github.com/sgl-project/sglang/commit/1eb40d8d458c5364d9c36204a866c77730ac4d4f)
- 受影响文件: .github/workflows/pr-test-npu.yml, test/srt/ascend/test_ascend_compile_graph_tp1_bf16.py, test/srt/ascend/test_ascend_deepep.py, test/srt/ascend/test_ascend_graph_tp1_bf16.py, test/srt/ascend/test_ascend_graph_tp2_bf16.py, test/srt/ascend/test_ascend_hicache_mha.py, test/srt/ascend/test_ascend_hicache_mla.py, test/srt/ascend/test_ascend_mla_fia_w8a8int8.py, test/srt/ascend/test_ascend_mla_w8a8int8.py, test/srt/ascend/test_ascend_tp2_bf16.py, test/srt/ascend/test_ascend_tp4_bf16.py, test/srt/run_suite.py
- [PD] Cleanup BootstrapServer init and ready check (#19551) [`366574b`](https://github.com/sgl-project/sglang/commit/366574b2b8fb4183b9ae29100c3f035ed04327e2)
- 受影响文件: python/sglang/srt/disaggregation/base/conn.py, python/sglang/srt/disaggregation/common/conn.py, python/sglang/srt/managers/disagg_service.py
- [NPU] bugfix: resolve modelslim load weights bug (#19472) [`4ebe9e1`](https://github.com/sgl-project/sglang/commit/4ebe9e1e2f630903a28a6c881b7a6901ea26f394)
- 受影响文件: python/sglang/srt/layers/quantization/modelslim/modelslim.py
- [diffusion] Postprocess: implement frame interpolation using RIFE (#19384) [`53c767d`](https://github.com/sgl-project/sglang/commit/53c767d224f0ae72e2d85ec8fce5775df58e32f1)
- 受影响文件: docs/diffusion/api/cli.md, python/sglang/multimodal_gen/configs/sample/sampling_params.py, python/sglang/multimodal_gen/runtime/entrypoints/diffusion_generator.py, python/sglang/multimodal_gen/runtime/entrypoints/http_server.py, python/sglang/multimodal_gen/runtime/entrypoints/openai/protocol.py, python/sglang/multimodal_gen/runtime/entrypoints/openai/utils.py, python/sglang/multimodal_gen/runtime/entrypoints/openai/video_api.py, python/sglang/multimodal_gen/runtime/entrypoints/utils.py, python/sglang/multimodal_gen/runtime/managers/gpu_worker.py, python/sglang/multimodal_gen/runtime/postprocess/__init__.py, python/sglang/multimodal_gen/runtime/postprocess/rife_interpolator.py, python/sglang/multimodal_gen/test/server/perf_baselines.json, python/sglang/multimodal_gen/test/server/test_server_utils.py, python/sglang/multimodal_gen/test/server/testcase_configs.py, python/sglang/multimodal_gen/test/test_utils.py
- [diffusion] CI: GT generation flow for diffusion CI (#19236) [`b01b07a`](https://github.com/sgl-project/sglang/commit/b01b07aa160f6043553c020b8db93d539715ec6c)
- 受影响文件: .github/workflows/diffusion-ci-gt-gen.yml, python/sglang/multimodal_gen/test/scripts/gen_diffusion_ci_outputs.py, python/sglang/multimodal_gen/test/scripts/gen_perf_baselines.py, python/sglang/multimodal_gen/test/server/test_server_common.py, python/sglang/multimodal_gen/test/server/test_server_utils.py, python/sglang/multimodal_gen/test/test_utils.py
- [PD] Support PD with context parallel after refactor (#19504) [`b01f359`](https://github.com/sgl-project/sglang/commit/b01f3590be819e6e86e9214738e411c673fa7fef)
- 受影响文件: python/sglang/srt/disaggregation/common/conn.py, python/sglang/srt/disaggregation/mooncake/conn.py, python/sglang/srt/disaggregation/prefill.py, python/sglang/srt/disaggregation/utils.py, python/sglang/srt/managers/scheduler_pp_mixin.py
- [AMD] Add triggering path for multimodal test in pr-test-amd (#19515) [`0404ef9`](https://github.com/sgl-project/sglang/commit/0404ef9023b601c287b5f7ef1de5ab6021550d6b)
- 受影响文件: .github/workflows/pr-test-amd-rocm720.yml, .github/workflows/pr-test-amd.yml
- [loader] support presharded fused mlp loading (#19519) [`79b1d2b`](https://github.com/sgl-project/sglang/commit/79b1d2bac68b250905cf13929a2d2372754c9ece)
- 受影响文件: python/sglang/srt/layers/linear.py
- feat(grpc): add multimodal TensorData parsing for vision inference (#19535) [`7162012`](https://github.com/sgl-project/sglang/commit/71620122c922c2e4e59412c4ee0c7f961bf02ac3)
- 受影响文件: python/sglang/srt/entrypoints/grpc_server.py
- [feat] Support nvfp4 quantized model of Qwen3-Next (#17627) [`a2ea594`](https://github.com/sgl-project/sglang/commit/a2ea5941d562faa5a9a20083ffc81dd0d9dd2d6a)
- 受影响文件: python/sglang/srt/models/qwen3_next.py, test/registered/models/test_qwen3_next_models_fp4.py
- [CLI] Add `--model-type` override and keep `launch_server` supported (#19523) [`ac400cb`](https://github.com/sgl-project/sglang/commit/ac400cb7bbcb810cd0e4fb11b2fa63b4185c8100)
- 受影响文件: python/sglang/cli/serve.py, python/sglang/cli/utils.py, python/sglang/launch_server.py
- [Session] Gate streaming sessions with `--enable-streaming-session` and spec v2 guard (#19531) [`e08ef06`](https://github.com/sgl-project/sglang/commit/e08ef06758af33a24c52cf51cc2b8cde312c89d5)
- 受影响文件: python/sglang/srt/managers/scheduler.py, python/sglang/srt/managers/scheduler_runtime_checker_mixin.py, python/sglang/srt/managers/tokenizer_communicator_mixin.py, python/sglang/srt/server_args.py, test/registered/sessions/test_session_control.py, test/registered/sessions/test_session_latency.py
- [SGL] sync patch: Remove sync points, prefill cudagraph for DP, disable cache reset in mem check (#19190) [`b5a8e41`](https://github.com/sgl-project/sglang/commit/b5a8e4179ea7577291ed2f11ad4563560fc9b66c)
- 受影响文件: python/sglang/srt/batch_overlap/two_batch_overlap.py, python/sglang/srt/connector/__init__.py, python/sglang/srt/layers/logits_processor.py, python/sglang/srt/managers/schedule_batch.py, python/sglang/srt/mem_cache/memory_pool.py, python/sglang/srt/model_executor/forward_batch_info.py, python/sglang/srt/model_executor/model_runner.py
- [CI] Nutanix LoRA adapter removed from HuggingFace (#19533) [`8c0f2d4`](https://github.com/sgl-project/sglang/commit/8c0f2d40bda1ea942a4f7f12f59b5625b7fcb471)
- 受影响文件: test/registered/perf/test_bench_serving_1gpu_part1.py
- Added the prefill delayer policy: The prefill deplay range is expanded. (#17456) [`5f07ff9`](https://github.com/sgl-project/sglang/commit/5f07ff92717ce7eba230ca7fc0ffab44ed255fe8)
- 受影响文件: python/sglang/srt/managers/prefill_delayer.py, python/sglang/srt/managers/schedule_policy.py, python/sglang/srt/managers/scheduler.py
- [Session] Add `streaming` mode with `SessionAwareCache` fast path (#19171) [`c6cb0c9`](https://github.com/sgl-project/sglang/commit/c6cb0c9649e1afedc8ef7ffda52bbf17d3b34454)
- 受影响文件: python/sglang/srt/entrypoints/engine.py, python/sglang/srt/managers/io_struct.py, python/sglang/srt/managers/schedule_batch.py, python/sglang/srt/managers/scheduler.py, python/sglang/srt/managers/scheduler_output_processor_mixin.py, python/sglang/srt/managers/scheduler_runtime_checker_mixin.py, python/sglang/srt/managers/session_controller.py, python/sglang/srt/mem_cache/common.py, python/sglang/srt/mem_cache/memory_pool.py, python/sglang/srt/mem_cache/session_aware_cache.py, test/registered/sessions/test_session_control.py, test/registered/sessions/test_session_latency.py
- [CI] Disable test_lora_update: Nutanix LoRA adapter removed from HuggingFace (#19527) [`2bd2b60`](https://github.com/sgl-project/sglang/commit/2bd2b60b5cdff59972318eb55f3deac8098cfc09)
- 受影响文件: test/registered/lora/test_lora_update.py
Issues：
- [Question] `clip_preprocess_text` seems to do nothing (https://github.com/sgl-project/sglang/issues/19525)
- [Bug] Qwen3-VL vision encoder produces incorrect output since v0.5.7 (https://github.com/sgl-project/sglang/issues/19513)
- Issue 内容已截断。
- [RFC] [Diffusion] SGLang Diffusion Disaggregation (https://github.com/sgl-project/sglang/issues/19512)
- Issue 内容已截断。
- [Bug] [dLLM] [Blackwell] Diffusion models (SDAR/Llada2.1 mini) Degradation on blackwell (https://github.com/sgl-project/sglang/issues/19508)
- Issue 内容已截断。
- [Feature] support pipeline parallelism for kimi-k2.5 (https://github.com/sgl-project/sglang/issues/19503)
- Issue 内容已截断。
- Question about sgl-kernel version (https://github.com/sgl-project/sglang/issues/19501)
- [Bug] Qwen3.5 does not work with pipeline parallelism (https://github.com/sgl-project/sglang/issues/19500)
- Issue 内容已截断。
- [Question] SGLang Diffusion cannot enable LoRA (https://github.com/sgl-project/sglang/issues/19494)
- Issue 内容已截断。
### vllm-project/vllm
**提交概览**

- **[#35621]**  <https://github.com/vllm-project/vllm/pull/35621>  
  *作者：Woosuk Kwon* – 为 Model Runner V2 引入 `ModelStateInterface`，并在 `vllm/v1/worker/gpu/model_states/` 新增 `interface.py`（67 行）与 `__init__.py`（18 行），重命名 `default.py`。  
  受影响模块：`model_runner.py`、`cudagraph_utils.py`（各 2 行改动）。

- **[#35557]**  <https://github.com/vllm-project/vllm/pull/35557>  
  *作者：Martin Vit* – 修复 Anthropic API 在 Messages 端点的 base64 图像处理。新增 326 行测试 `tests/entrypoints/openai/test_anthropic_messages_conversion.py`，`serving.py` 增加 63 行、删除 5 行。  

- **[#35620]**  <https://github.com/vllm-project/vllm/pull/35620>  
  *作者：Isotr0py* – 清理 BNB 相关死代码，`linear.py` 删除 39 行。  

- **[#35441]**  <https://github.com/vllm-project/vllm/pull/35441>  
  *作者：Wentao Ye* – 0.17 版代码弃用，涉及多处 entrypoint 与协议文件的删改（共计约 250 行删除）。  

- **[#35618]**  <https://github.com/vllm-project/vllm/pull/35618>  
  *作者：Cyrus Leung* – 基准测试中避免不必要的视频下载，`datasets.py` 增加 12 行。  

- **[#35405]**  <https://github.com/vllm-project/vllm/pull/35405>  
  *作者：emricksini-h* – 在多阶段并行（PP）中阻止图像输入被发送到非首层，修改 `ray_utils.py`（+12 行）。  

- **[#35581]**  <https://github.com/vllm-project/vllm/pull/35581>  
  *作者：cwazai* – 修正 Qwen3_5MTP `packed_modules_mapping` 中 `gate_up_proj` 的实现，单行改动。  

- **[#35280]**  <https://github.com/vllm-project/vllm/pull/35280>  
  *作者：flutist* – 为自定义数据集添加 base64 图像支持，`datasets.py` 改动 14 行（+8 / -6）。  

- **[#35271]**  <https://github.com/vllm-project/vllm/pull/35271>  
  *作者：Chauncey* – 为 `fp8_mqa_logits` / `fp8_paged_mqa_logits_torch` 添加 CUDA fallback，实现 176 行新增代码（`sparse_attn_indexer.py`、`deep_gemm.py`、`indexer.py`）。  

- **[#34214]**  <https://github.com/vllm-project/vllm/pull/34214>  
  *作者：Augusto Yao* – 新增稀疏嵌入插件 `bge_m3_sparse_plugin`，包括 6+135+32 行实现文件及对应测试。  

- **[#33671]**  <https://github.com/vllm-project/vllm/pull/33671>  
  *作者：Mario Hong* – 支持 Anthropic “Thinking Block”，`protocol.py` +10/-2 行，`serving.py` 大幅改动（+226/-95 行）。  

- **[#33762]**  <https://github.com/vllm-project/vllm/pull/33762>  
  *作者：Hashem Hashemi* – 为 skinny GEMM 添加 padding 支持，`skinny_gemms.cu` 变更 658 行（+256 / -402），相应测试更新。  

- **[#35571]**  <https://github.com/vllm-project/vllm/pull/35571>  
  *作者：Andreas Karatzas* – 在 ROCm CI 中为视觉评分测试加入后端容差参数，`test_online_score_vision.py` 改动 193 行。  

- **[#35600]**  <https://github.com/vllm-project/vllm/pull/35600>  
  *作者：Cyrus Leung* – 改进 sweep 脚本 UX，文档与脚本共计 319 行改动。  

- **[#35586]**  <https://github.com/vllm-project/vllm/pull/35586>  
  *作者：Cyrus Leung* – 将 SLA Finder 重命名为 Workload Explorer，文档与实现共计 232 行改动。  

- **[#35575]**  <https://github.com/vllm-project/vllm/pull/35575>  
  *作者：Chauncey* – 将工具解析器日志级别从 `info` 调整为 `debug`（`qwen3coder_tool_parser.py` +1/-1 行）。  

- **[#35589]**  <https://github.com/vllm-project/vllm/pull/35589>  
  *作者：Chauncey* – CI 中为 MockWeightTransferEngine 添加 `trainer_send_weights`，测试文件小幅改动（+4 行）。  

- **[#35071]**  <https://github.com/vllm-project/vllm/pull/35071>  
  *作者：Andreas Karatzas* – 在 AMD CI 中公开测试并修复 amdsmi 堆损坏，`.buildkite/test-amd.yaml` 变更 94 行。  

- **[#35069]**  <https://github.com/vllm-project/vllm/pull/35069>  
  *作者：Andreas Karatzas* – ROCm 平台通过 GCN 架构字符串推断设备能力，`platforms/rocm.py` 增加 104 行。  

- **[#35170]**  <https://github.com/vllm-project/vllm/pull/35170>  
  *作者：Andreas Karatzas* – 为 MORIIO 测试添加 infiniband 映射，脚本改动 194 行。  

- **[#35212]**  <https://github.com/vllm-project/vllm/pull/35212>  
  *作者：Ilya Markov* – 对 NCCL 基于 all2all 后端强制同步 EPLB，`config/parallel.py` +11 行。  

- **[#35510]**  <https://github.com/vllm-project/vllm/pull/35510>  
  *作者：Umut Polat* – 将 `response_format` 验证迁移至 Pydantic `model_validator`，`protocol.py` +28 行。  

- **[#35503]**  <https://github.com/vllm-project/vllm/pull/35503>  
  *作者：Huy Do* – 在 TP>1 场景下传播 `compilation_time`，涉及抽象执行器与工作线程文件共计 25 行改动。  

- **[#34861]**  <https://github.com/vllm-project/vllm/pull/34861>  
  *作者：Itay Alroy* – Elastic EP 第 2 阶段里程碑，新增大量分布式测试（`test_elastic_ep.py` 202 行等），并更新 CI 配置。  

- **[#35466]**  <https://github.com/vllm-project/vllm/pull/35466>  
  *作者：Ma Jian* – CPU Release 支持 AVX2 与 AVX512 双编译，CMake 与源码共计 308 行改动。  

- **[#35548]**  <https://github.com/vllm-project/vllm/pull/35548>  
  *作者：Matthew Bonanni* – 为 MTP 权重加载添加校验，`deepseek_mtp.py` +20 行。  

- **[#35537]**  <https://github.com/vllm-project/vllm/pull/35537>  
  *作者：Cyrus Leung* – SLA Finder（现 Workload Explorer）修复，文档与脚本共计 86 行改动。  

- **[#35527]**  <https://github.com/vllm-project/vllm/pull/35527>  
  *作者：Micah Williamson* – 为 ROCm 添加 `stablelm` Head Size 80 支持，相关文件各 1 行改动。  

- **[#34301]**  <https://github.com/vllm-project/vllm/pull/34301>  
  *作者：Douglas Lehr* – 为 MXFP4 量化加入 Composable Kernel 后端，`_aiter_ops.py` +160 行，`mxfp4.py` +100 行。  

- **[#35564]**  <https://github.com/vllm-project/vllm/pull/35564>  
  *作者：Woosuk Kwon* – 将 MM 编码器迁移至 Model States（第 3/4 步），涉及 `encoder_cache.py`（+40 行）等多个 GPU worker 文件共计 246 行改动。  

- **[#35120]**  <https://github.com/vllm-project/vllm/pull/35120>  
  *作者：Woosuk Kwon* – 为 pooling 模型提供支持，新增 `pool/` 包及 `pooling_runner.py`（+45 行），并在 `model_runner.py` 中加入相应逻辑（+90 行）。  

- **[#35531]**  <https://github.com/vllm-project/vllm/pull/35531>  
  *作者：Umut Polat* – 清理 `ResponsesRequest` 的模型校验器，`protocol.py` +14/-5 行。  

> **说明**：部分提交的 `patch` 被标记为 `patch_truncated: true`，因此未展示完整 diff，仅依据文件增删统计提供概览。

---

**Issues 关注点**

- **[#35562] MXFP4A16 量化出现极端退化**  
  <https://github.com/vllm-project/vllm/issues/35562>  
  *作者：zeryx* – 在 Qwen3-30B-A3B MoE 模型上使用 MXFP4A16 量化后，perplexity 从 8.74（BF16）飙升至 22,953，怀疑 Marlin 后端实现错误。  

- **[#35550] RFC：批量感知专家剪枝（XShare）**  
  <https://github.com/vllm-project/vllm/issues/35550>  
  *作者：hai-meh-cs* – 提议在 MoE 解码阶段根据整批 token 的专家需求进行预算裁剪，以降低显存占用并提升吞吐。  

- **[#35547] 长时间权重加载导致服务器启动失败**  
  <https://github.com/vllm-project/vllm/issues/35547>  
  *作者：wzhao18* – 在大模型启动时，权重加载耗时过长导致服务异常退出，已有两条评论讨论潜在的 I/O 优化。  

- **[#35544] CI 失败：test_utils.py 导入错误**  
  <https://github.com/vllm-project/vllm/issues/35544>  
  *作者：dippi9845* – CI 环境中 `tests/utils.py` 的导入路径错误，导致所有测试中断。  

- **[#35541] 低 `num_gpu_blocks_override` 导致 vLLM 卡死**  
  <https://github.com/vllm-project/vllm/issues/35541>  
  *作者：kvcache670* – 当 `num_gpu_blocks_override` 设置过低时，调度器进入死循环，已有人提出可能的锁竞争问题。
### NVIDIA/cutile-python
提交：
- Fix DeprecationWarning regarding throw() on pytests [`59e46ce`](https://github.com/NVIDIA/cutile-python/commit/59e46ce495aac907980727d46ba5415e27980d37)
- 受影响文件: src/cuda/tile/_coroutine_util.py, src/cuda/tile/_stub.py, test/test_coroutine_util.py

## 总结
总体来看，核心算子库（cutlass、flash-attention）和大模型服务框架（vllm、sglang）正同步推进跨硬件（GPU、AMD、NPU）适配与性能调优，尤其是对新架构（SM100、Blackwell）和量化格式（FP8、MXFP4）的支持将成为下阶段的关键突破点。建议关注 **vllm** 中的 `num_gpu_blocks_override` 参数调优风险以及 **cutlass** 对 INT8/FP8 GEMM 的未来路线图，以提前规避潜在的部署不稳定性。
